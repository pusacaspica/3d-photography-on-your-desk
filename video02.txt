Boa noite, meu nome é Horácio Macêdo, e junto do colega Issufi, ficamos de implementar o trabalho escrito por Bougie e Perona em 1998 no trabalho 3d photography on your desk onde, usando apenas uma fonte de luz, uma sombra e um objeto para projetar sombra, cria-se um scanner 3d. Este vídeo está sendo regravado porque coisas aconteceram nesta semana que passou, o que tornou o último vídeo obsoleto.

No formulário anterior, nós falamos que um bom indicativo de andamento do trabalho a curto prazo seria ter posse de uma nuvem de pontos, e o objetivo a longo prazo seria a obtenção da malha final. Nós realmente subestimamos o trabalho que a gente teria, e as dificuldades que encontraríamos, mas depois desta última semana, eu acho que estamos num lugar melhor do que eu achei que estivéssemos originalmente.

No atual momento do trabalho, nós temos o mapeamento espaço-temporal de sombras, que a gente compreende ser a parte principal do trabalho. Depois de um mês entendendo como usar ndarrays direito para que o processamento não demorasse horas inteiras, nós conseguimos implementar funções que nos entrega tanto as coordenadas da sombra em cada frame do vídeo, como também o tempo em que a sombra intercepta cada pixel da imagem. Também coletamos informações necessárias para calibração de câmeras, que deve dar início agora que a dúvida da semana passada foi sanada e, ao mesmo tempo, abriu toda uma família nova de dúvidas que provavelmente são respondidas em algum dos livros-textos. O artigo de Tsai, ao mesmo tempo em que deu uma boa ideia do processo envolvido ao redor de calibração de câmeras, nos deixou com dúvida sobre como usar a matriz de calibração da câmera na real calibração da câmera.

Também há dúvida em como apropriadamente isolar a família de planos usadas para mapeamento dos vértices. Enquanto que o matplotlib nos fornece um conjunto de funções que serão usadas para a reconstrução das malhas, "fazer a intersecção do plano indexado pelo mapeamento temporal de um pixel com o raio ótico" ainda é algo que nos dá alguma dúvida.

Na implementação atual, o mapeamento temporal está definindo coordenadas de vértices de modo que o t é usado como coodenada de profundidade, tomando como referência o plano da imagem. Claramente, os modelos não estão tão legais assim, e a gente meio que só tem uma malha de pontos até agora mesmo.